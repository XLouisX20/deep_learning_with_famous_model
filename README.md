# Pytorch 實作系列

文章同步發布在個人部落格(https://gite0z9.github.io)

此專案初衷是實作多年來學習的深度學習模型，並提供 notebook 跟 medium 文章學習，而非一個專注於特定領域的 production-ready 庫

接下來的開發方向會往 monorepo 延伸

[english-version](https://github.com/gitE0Z9/pytorch-implementations/blob/main/README.en.md)

[中文版本](https://github.com/gitE0Z9/pytorch-implementations/blob/main/README.md)

<table>
  <tr>
    <th>領域(domain)</th>
    <th>模型(model)</th>
  </tr>
  <tr>
    <td>
      <b>少樣本學習(few shot learning)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%B8%80-siamese-network-c06dc78242ed">
            Siamese network
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-13-prototypical-network-360f0e411d21">
            Prototypical network
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>圖像分類(image classification)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%B8%83-resnet-690868d7af43">
            ResNet50
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>物件偵測(object detection)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/object-detection-from-scratch-with-pytorch-yolov1-a56b49024c22">
            YOLOv1
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/object-detection-from-scratch-with-pytorch-yolov2-722c4d66cd43">
            YOLOv2
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>語意分割(semantic segmentation)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E5%8D%81-unet-545efa00ad99">
            UNet
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-fcn-89cac059179b">
            FCN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>圖像生成(image generation)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%BA%8C-variational-autoencoder-954596aae539">
            VAE
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%B8%89-generative-adversarial-network-445ffdc297fd">
            GAN
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-11-dcgan-40a78e279030">
            DCGAN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>光學文字辨識(optical character recognition)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch-%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-crnn-b2a7a8fa1698">
            CRNN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>風格遷移(style transfer)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%B9%9D-image-style-transfer-371e161c5620">
            Neural style transfer
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-neural-doodle-80bb55108836">
            Neural Doodle
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch-%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-fast-style-transfer-6630af677395">
            Fast style transfer
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch-%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-adain-f18fd4bca76b">
            AdaIN
          </a>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-14-pix2pix-5b550c1fbb39">
            Pix2pix
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>文本分類(text classification)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E4%BA%94-textcnn-cd9442139f8c">
            TextCNN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>詞性標注(POS tagging)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch-%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-bilstm-92d8e01d488e">
            BiLSTM
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>命名實體辨識(named entity recognition)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/pytorch-%E5%AF%A6%E4%BD%9C%E7%B3%BB%E5%88%97-bilstm-crf-7d2014a286f6">
            BiLSTM-CRF
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>機器翻譯(machine translation)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E5%85%AD-sequence-to-sequence-327886dafa4">
            Seq2Seq
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>增強學習(reinforcement learning)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E5%85%AB-deep-q-network-b12d7769e337">
            DQN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>序列資料(sequence data)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-%E5%9B%9B-long-short-term-memory-21c097616641">
            LSTM
          </a>
        </li>
        <li>
          <p>GRU</p>
        </li>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/%E7%B6%93%E5%85%B8%E7%B6%B2%E8%B7%AF%E7%B3%BB%E5%88%97-12-temporal-convolutional-network-799a243ffa2d">
            TCN
          </a>
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <td>
      <b>語言模型(language model)</b>
    </td>
    <td>
      <ul>
        <li>
          <a href="https://acrocanthosaurus627.medium.com/language-model-from-scratch-with-pytorch-word2vec-10e77770cc57">
            Word2vec
          </a>
        </li>
      </ul>
    </td>
  </tr>
</table>

## 安裝方式

`pip install .`

## 專案結構

`notebooks`: 展示如何使用 torchlake.

`torchlake`: 由不同應用領域組成的深度學習包.

每個領域大致上會有如下結構

```
├───adapter
├───artifacts
│   └───model_name
├───configs
│   └───model_name
├───constants
├───controller
├───datasets
│   └───dataset_name
├───models
│   ├───base
│   └───model_name
│       ├───model.py
│       ├───network.py
│       ├───loss.py
│       └───decode.py
├───reference
│   └───model_name
│       └───paper
├───runs
├───scripts
│   └───debug
├───tests
├───utils
└───requirements.txt
```

`adapter`: 介接 controller 和其他資源(model, model.loss, etc.)

`configs`: 模型設定檔，包括裝置定義、模型定義、訓練定義、推論定義，共四個面向

`constants`: 固定的值，包括 constant 和 enum

`controller`: 控制器，`controller`是共用基底，`trainer`、`evaluator`、`predictor`負責訓練、評估、預測三種工作

`models`: 模型定義，`network.py`是模型區塊，`model.py`是最後組裝的模型，`loss.py`是損失函數

`datasets`: 資料集，目前是照領域區分，有分 raw dataset 和 csv dataset，前者是讀取 raw data，後者是讀取處理過的 csv(如歸一化座標)

`runs`: 記載`trainer`和`evaluator`的結果的 tensorboard log 資料夾

`tests`: 單元測試，使用 `pytest`

`utils`: 存放依賴性低且復用性高的函式

model 和 dataset 的 config 會用 `pydantic` 控制格式
