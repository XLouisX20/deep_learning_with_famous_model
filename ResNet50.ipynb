{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = torchvision.datasets.ImageFolder('animal10/',transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(datas,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, first_dim, second_dim, output_dim):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(input_dim,first_dim,1),\n",
    "            nn.Conv2d(first_dim,second_dim,3,padding=1),\n",
    "            nn.Conv2d(second_dim,output_dim,1)\n",
    "        )\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, output_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tmp = self.block(x)\n",
    "        if self.input_dim != self.output_dim:\n",
    "            res = self.downsample(x)\n",
    "        else:\n",
    "            res = x\n",
    "        tmp = tmp + res\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.foot = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,stride=2, padding = 5),\n",
    "            nn.MaxPool2d(3,stride=2)\n",
    "        )\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBlock(64,64,64,256),\n",
    "            ConvBlock(256,64,64,256),\n",
    "            ConvBlock(256,64,64,256)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBlock(256,128,128,512),\n",
    "            ConvBlock(512,128,128,512),\n",
    "            ConvBlock(512,128,128,512),\n",
    "            ConvBlock(512,128,128,512),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            ConvBlock(512,256,256,1024),\n",
    "            ConvBlock(1024,256,256,1024),\n",
    "            ConvBlock(1024,256,256,1024),\n",
    "            ConvBlock(1024,256,256,1024),\n",
    "            ConvBlock(1024,256,256,1024),\n",
    "            ConvBlock(1024,256,256,1024),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            ConvBlock(1024,512,512,2048),\n",
    "            ConvBlock(2048,512,512,2048),\n",
    "            ConvBlock(2048,512,512,2048),\n",
    "            nn.AvgPool2d(2,2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048*7*7,10)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        tmp = self.foot(x)\n",
    "        tmp = self.block1(tmp)\n",
    "        tmp = self.block2(tmp)\n",
    "        tmp = self.block3(tmp)\n",
    "        tmp = self.block4(tmp)\n",
    "        tmp = torch.flatten(tmp,start_dim=1)\n",
    "        tmp = self.fc(tmp)\n",
    "\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(8,3,224,224).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3273/3273 [23:40<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 3765.3061668872833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "training_loss = []\n",
    "for e in range(epoches):\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(loader):\n",
    "        img, label = data\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        output = model(img)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "    training_loss.append(running_loss/len(data))\n",
    "    print(f'epoch {e+1}: {running_loss/len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3273/3273 [05:21<00:00, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07146949845295848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    running_hit = 0.0\n",
    "    for data in tqdm(loader):\n",
    "        img, label = data\n",
    "        img = img.cuda()\n",
    "        \n",
    "        output = model(img)\n",
    "        output = output.detach().cpu()\n",
    "        output = output.argmax(dim=1)\n",
    "        acc = torch.sum(label == output)\n",
    "        running_hit += acc.item()\n",
    "    print(running_hit/len(datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict('resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netron 檢查\n",
    "torch.onnx.export(model.cpu(),torch.randn(1,3,224,224),'a.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
