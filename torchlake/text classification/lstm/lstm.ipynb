{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.data.utils import get_tokenizer, ngrams_iterator\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu118'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.16.0+cpu'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_idex = 0\n",
    "bos_idx = 1\n",
    "eos_idx = 2\n",
    "padding_idx = 3\n",
    "min_seq_len = 5\n",
    "max_seq_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "min_frequency = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapipe_factory(datapipe, transform = None):\n",
    "    datapipe = (\n",
    "        datapipe\n",
    "        .map(lambda item: (item[0], item[1].strip()) )\n",
    "        .map(lambda item: (item[0], item[1].lower()) )\n",
    "        .filter(lambda item: len(item[1]) > min_seq_len)\n",
    "        .map(lambda item: (item[0], tokenizer(item[1])) )\n",
    "        # .map(lambda text: drop_keywords(text, stopwords.words('english')))\n",
    "        # .filter(lambda tokens: drop_short_text(tokens, context_size))\n",
    "    )\n",
    "\n",
    "    if transform:\n",
    "      datapipe = datapipe.map(lambda item: (item[0], transform(item[1])))\n",
    "\n",
    "    return datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe, test_datapipe = torchtext.datasets.IMDB(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\research\\pytorch-implementations\\.venv\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:141: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab_from_iterator(map(lambda x: x[1], datapipe_factory(test_datapipe)), specials=[\"<unk>\", \"<bos>\", \"<eos>\", \"<pad>\"], min_freq=min_frequency,)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = T.Sequential(\n",
    "    T.VocabTransform(vocab),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    "    T.ToTensor(),\n",
    "    T.PadTransform(max_seq_len, padding_idx),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe = datapipe_factory(\n",
    "    train_datapipe,\n",
    "    text_transform,\n",
    ")\n",
    "\n",
    "test_datapipe = datapipe_factory(\n",
    "    test_datapipe,\n",
    "    text_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: list):\n",
    "    text_placeholder, label_placeholder = [], []\n",
    "    for (label, text) in batch:\n",
    "        text_placeholder.append(text)\n",
    "        label_placeholder.append(label)\n",
    "\n",
    "    return torch.stack(text_placeholder), torch.Tensor(label_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_datapipe,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_datapipe,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for text, label in train_dataloader:\n",
    "    print(text.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29575"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim:int, hidden_dim:int):\n",
    "        super(LSTM_Classifier,self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        output = self.embed(x) # batch_size, seq_len, embed_dim \n",
    "        # ot: batch_size, seq_len, bidirectional*hidden_dim\n",
    "        # ht: bidirectional * layer_size, batch_size, hidden_dim \n",
    "        _, (ht, _) = self.rnn(output)\n",
    "        output = self.fc(ht[-1]) # the last layer's hidden state represents the paragraph\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "model = LSTM_Classifier(embed_dim, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1])\n"
     ]
    }
   ],
   "source": [
    "## 測試 forward\n",
    "for batch in train_dataloader:\n",
    "    text, label = batch\n",
    "    text = text.to(device)\n",
    "    output = model(text)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "training_loss = []\n",
    "for epoch in range(epoches):\n",
    "    running_loss = 0.0\n",
    "    batch_idx = 0\n",
    "    for batch in tqdm(test_dataloader):    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text, label = batch\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(text).squeeze(1)\n",
    "        loss = criterion(output, label-1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        batch_idx += 1\n",
    "\n",
    "    mean_running_loss = running_loss/batch_idx\n",
    "    training_loss.append(mean_running_loss)\n",
    "    print(f'epoch {epoch+1} : {mean_running_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    running_hit = 0.0\n",
    "    data_size = 0\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        text, label = batch\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        output = model(text).squeeze(1)\n",
    "        pred = output.sigmoid() > 0.5\n",
    "        running_hit += (pred == (label-1)).sum().item()\n",
    "        data_size += text.size(0)\n",
    "\n",
    "    print(running_hit/data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3088]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(text_transform(tokenizer(\"It was such a good movie I have ever seen\")).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3088]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(text_transform(tokenizer(\"So bad a movie can be, waste my money\")).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
