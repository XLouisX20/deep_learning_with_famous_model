{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from typing import List, Dict\n",
    "from collections import Counter\n",
    "from seaborn import heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('../data/NER_dataset/ner_dataset.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Sentence #'] = x['Sentence #'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is seriously important, which can save you hours\n",
    "x = x.set_index('Sentence #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best groupby speedup for now\n",
    "new_df = x.groupby(level=(0)).apply(lambda x: [x['Word'].str.cat(sep=' '), x['Tag'].str.cat(sep=' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be improved\n",
    "new_df = pd.DataFrame([d for d in new_df],columns=['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_func(dataset: pd.DataFrame, x_or_y: str) -> List[str]:\n",
    "    \n",
    "    for text, label in dataset:\n",
    "        if x_or_y == 'x':\n",
    "            yield tokenizer(text)\n",
    "        elif x_or_y == 'y':\n",
    "            yield tokenizer(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat([torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collate data samples into batch tesors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform(src_sample))\n",
    "        tgt_batch.append(label_transform(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, x_transform=None, y_transform=None):\n",
    "        self.data = data\n",
    "        self.transform = (x_transform,y_transform)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text, label = self.data[idx]\n",
    "        \n",
    "        if self.transform[0] and self.transform[1]:\n",
    "            x, y = self.transform\n",
    "            text = x(text)\n",
    "            label = y(label)\n",
    "        \n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../data/NER_dataset/train.csv').dropna().to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(lambda a: a.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocab = build_vocab_from_iterator(iter_func(training_data,'x'), \n",
    "                                            specials=special_tokens,\n",
    "                                            special_first=True)\n",
    "    \n",
    "text_vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = build_vocab_from_iterator(iter_func(training_data,'y'), \n",
    "                                            specials=special_tokens,\n",
    "                                            special_first=True)\n",
    "    \n",
    "label_vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = sequential_transforms(tokenizer, text_vocab, tensor_transform)\n",
    "label_transform = sequential_transforms(tokenizer, label_vocab, tensor_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(yhat, transition_matrix, mask=None):\n",
    "    \"\"\"\n",
    "    forward backward algorithm\n",
    "    \n",
    "    viterbi forward: path score\n",
    "    backward: find token\n",
    "    \n",
    "    \"\"\"\n",
    "    seq_len, batch_size, label_size = yhat.size()\n",
    "\n",
    "    backpointers = []\n",
    "\n",
    "    # forward\n",
    "    init_vvars = torch.full((batch_size, label_size), LIKELIHOOD_INIT)\n",
    "    init_vvars[:,BOS_IDX] = 0\n",
    "    \n",
    "    for s, feat in enumerate(yhat):\n",
    "        # batch_size, next_tag, current_tag\n",
    "        viterai_t = init_vvars.unsqueeze(1) +transition_matrix.unsqueeze(0) # B,1,L + 1,L,L \n",
    "        viterai_t, bkptr_t = torch.max(viterai_t, -1) # B,L\n",
    "        viterai_t += feat #B,L\n",
    "        backpointers.append(bkptr_t) #S x B,L\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask_t = mask[s].unsqueeze(-1)  # B, 1\n",
    "        else:\n",
    "            mask_t = torch.ones(batch_size,1).to(device)\n",
    "        \n",
    "        init_vvars = viterai_t * mask_t.long() + init_vvars * (1 - mask_t.long()) #B,L\n",
    "        \n",
    "    backpointers = torch.stack(backpointers, 0) # S, B, L\n",
    "    init_vvars += transition_matrix[EOS_IDX].unsqueeze(0) # 1, L\n",
    "    best_score, best_tag = torch.max(init_vvars, -1)  # B\n",
    "    \n",
    "    # backtracking\n",
    "    best_path = best_tag.unsqueeze(-1).tolist() # B,1\n",
    "    for i in range(batch_size):\n",
    "        best_tag_i = best_tag[i] # 1\n",
    "        seq_len_i = int(mask[:, i].sum()) if mask is not None else len(yhat)\n",
    "        for ptr_t in reversed(backpointers[:seq_len_i, i]): # S, L\n",
    "            best_tag_i = ptr_t[best_tag_i].item() # S+1 x L\n",
    "            best_path[i].append(best_tag_i)\n",
    "        # pop first tag\n",
    "        best_path[i].pop() #B,S,L\n",
    "        # reverse order\n",
    "        best_path[i].reverse()\n",
    "    \n",
    "    return best_score, best_path # B # B,S,L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size:int, label_num:int, embedding_dim:int, hidden_dim:int):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tagset_size = label_num\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True)\n",
    "        self.ln = nn.LayerNorm(hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        \n",
    "        # transition matrix\n",
    "        # store not prob but log likelihood \n",
    "        # from j to i !?\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size).to(device))\n",
    "        # never transfer to the start tag\n",
    "        self.transitions.data[BOS_IDX, :] = LIKELIHOOD_INIT\n",
    "        # never transfer from the start to the end\n",
    "        self.transitions.data[EOS_IDX, BOS_IDX] = LIKELIHOOD_INIT\n",
    "        # never transfer from the eos\n",
    "        self.transitions.data[:, EOS_IDX] = LIKELIHOOD_INIT\n",
    "        \n",
    "\n",
    "    def get_token_output(self, sentences):\n",
    "        \"\"\"token classfication\"\"\"\n",
    "        mask = sentences.ne(PAD_IDX)\n",
    "        mask_length, mask_order = mask.sum(0).sort(descending=True)\n",
    "        embeds = self.word_embeds(sentences)[:,mask_order,:]\n",
    "        embeds = pack_padded_sequence(embeds, mask_length)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out) # S, B, H\n",
    "        lstm_out = self.ln(lstm_out * mask.unsqueeze(-1))\n",
    "        lstm_feats = self.hidden2tag(lstm_out * mask.unsqueeze(-1)) * mask.unsqueeze(-1) # S, B, L\n",
    "        _, sort_back = mask_order.sort()\n",
    "        lstm_feats = lstm_feats[:,sort_back,:]\n",
    "        return lstm_feats\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "\n",
    "        lstm_feats = self.get_token_output(sentence)\n",
    "        \n",
    "        return lstm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customloss(nn.Module):\n",
    "    \n",
    "    def __init__(self, label_num: int):\n",
    "        super(customloss,self).__init__()\n",
    "        self.target_size = label_num\n",
    "        \n",
    "    # Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "    @staticmethod\n",
    "    def log_sum_exp(x):\n",
    "        \"\"\"log softmax\"\"\"\n",
    "        max_score, _ = x.max(-1, keepdim=True) # B, L, 1\n",
    "        return max_score + torch.exp(x - max_score).sum(-1, keepdim=True).log()\n",
    "        \n",
    "    def forward_alg(self, yhat, mask, transition_matrix):\n",
    "        \"\"\"yhat on its own\"\"\"\n",
    "        \n",
    "        seq_len, batch_size, _ = yhat.shape\n",
    "        \n",
    "        # batch_size, label_size\n",
    "        alpha = torch.full((batch_size, self.target_size), LIKELIHOOD_INIT).to(device)\n",
    "        # BOS has all of the score.\n",
    "        alpha[:, BOS_IDX] = 0\n",
    "\n",
    "        # batch_size, next_tag, current_tag\n",
    "        for s, feat in enumerate(yhat):\n",
    "            \n",
    "            emit_score = feat.unsqueeze(-1) # B, L, 1\n",
    "            transition_score = transition_matrix.unsqueeze(0) # 1, L, L\n",
    "            alpha_score = alpha.unsqueeze(1) # B, 1, L\n",
    "            \n",
    "            alpha_score = alpha_score + transition_score + emit_score #B,L,L\n",
    "            mask_t = mask[s].unsqueeze(-1) # B,1\n",
    "            alpha = self.log_sum_exp(alpha_score).squeeze(-1) * mask_t.long() + alpha * (1 - mask_t.long()) # B, L\n",
    "                    \n",
    "        alpha = alpha + transition_matrix[EOS_IDX].unsqueeze(0) # B,L + 1, L\n",
    "        \n",
    "        return self.log_sum_exp(alpha).squeeze(-1) # B\n",
    "                \n",
    "    def score_sentence(self, yhat, y, mask, transition_matrix):\n",
    "        \"\"\"yhat with true path\"\"\"\n",
    "        \n",
    "        assert y.size(0) == yhat.size(0), f'misaligned seq length {y.size(0)}, {yhat.size(0)}'\n",
    "        assert y.size(1) == yhat.size(1), 'misaligned batch size'\n",
    "        assert yhat.size(2) == len(label_vocab), 'wrong yhat label size'\n",
    "        \n",
    "        seq_len, batch_size = y.size()\n",
    "        scores = torch.zeros(batch_size).to(device)\n",
    "        start_tag = torch.full((1, batch_size), fill_value=BOS_IDX)\n",
    "        y = torch.cat([start_tag,y],0) # S+1, B\n",
    "        \n",
    "        for s, feat in enumerate(yhat):\n",
    "            emit_score = torch.stack([f[next_tag] for f, next_tag in zip(feat, y[s + 1])]) # B, L\n",
    "            transition_score = torch.stack([transition_matrix[y[s + 1, b], y[s, b]] for b in range(batch_size)]) # B\n",
    "            scores += (emit_score + transition_score) * mask[s] # B\n",
    "        transition_to_end = torch.stack([transition_matrix[EOS_IDX, tag[mask[:, b].sum().long()]] for b, tag in enumerate(y.transpose(0, 1))])\n",
    "        scores += transition_to_end\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "        \n",
    "    def forward(self, yhat, y, mask, transition_matrix):\n",
    "                \n",
    "        forward_score = self.forward_alg(yhat, mask, transition_matrix)\n",
    "        \n",
    "        gold_score = self.score_sentence(yhat, y, mask, transition_matrix)\n",
    "                        \n",
    "        return (forward_score - gold_score).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHES = 10\n",
    "BATCH_SIZE = 128\n",
    "device = 'cpu'\n",
    "LIKELIHOOD_INIT = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NERDataset(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(len(text_vocab), len(label_vocab), EMBEDDING_DIM, HIDDEN_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = customloss(len(label_vocab))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:20<00:00,  1.87it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 12779.68973628516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:31<00:00,  1.78it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: 9992.40908249755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:32<00:00,  1.77it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: 9422.148295940282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:32<00:00,  1.77it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: 8173.158721512125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:33<00:00,  1.76it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: 6635.433308920119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:32<00:00,  1.77it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: 4478.236309920974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:32<00:00,  1.76it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: 3899.988939119873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:34<00:00,  1.75it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: 3622.9017070570694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:35<00:00,  1.74it/s]\n",
      "  0%|                                                                                          | 0/375 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: 3344.912685835818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [03:37<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: 3209.1510746809777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCHES):\n",
    "    running_loss = 0\n",
    "    for datas in tqdm(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        sentence, tags = datas\n",
    "        sentence = sentence.to(device)\n",
    "        tags = tags.to(device)        \n",
    "        \n",
    "        output = model(sentence)\n",
    "        \n",
    "        loss = criterion(output, tags, sentence.ne(PAD_IDX), model.transitions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        running_loss += loss.item()\n",
    "                            \n",
    "    print(f'epoch {epoch+1}: {running_loss/len(training_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'crf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('crf.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- 0\n",
      "score:  -2212.620849609375\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     B-geo O     O     O     O     O     B-geo O     O     O     O     O     B-gpe O     O     O     O     O    \n",
      "text :  Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "\n",
      "-------------- 1\n",
      "score:  -1754.36865234375\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-tim O     O     O     O     O     O     O     O     O    \n",
      "label:  B-gpe O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-tim O     O     O     B-org O     O     O     O     O    \n",
      "text :  Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an IAEA surveillance system begins functioning .\n",
      "\n",
      "-------------- 2\n",
      "score:  -1561.9033203125\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     O     O     O     B-gpe O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-gpe O     O     O    \n",
      "label:  O     O     B-tim O     O     O     O     O     B-geo O     O     O     O     O     B-org O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-geo I-geo O    \n",
      "text :  Helicopter gunships Saturday pounded militant hideouts in the Orakzai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South Waziristan .\n",
      "\n",
      "-------------- 3\n",
      "score:  -802.2626953125\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     O     O     O     O     O    \n",
      "text :  They left after a tense hour-long standoff with riot police .\n",
      "\n",
      "-------------- 4\n",
      "score:  -4997.7861328125\n",
      "pred :  B-geo B-per I-org I-org O     O     B-tim O     B-geo O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  B-geo O     O     B-per I-per O     B-tim O     B-geo O     B-gpe O     B-gpe O     O     O     O     O     O     O     O     O     O     O     O     O     B-geo O     O     O     O     O     O     O     O    \n",
      "text :  U.N. relief coordinator Jan Egeland said Sunday , U.S. , Indonesian and Australian military helicopters are ferrying out food and supplies to remote areas of western Aceh province that ground crews can not reach .\n",
      "\n",
      "-------------- 5\n",
      "score:  -1695.6279296875\n",
      "pred :  B-per O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-tim O    \n",
      "label:  B-per I-per O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-tim O     B-per B-gpe O     O     B-geo O     B-geo O    \n",
      "text :  Mr. Egeland said the latest figures show 1.8 million people are in need of food assistance - with the need greatest in Indonesia , Sri Lanka , the Maldives and India .\n",
      "\n",
      "-------------- 6\n",
      "score:  -965.42138671875\n",
      "pred :  O     O     O     O     O     B-gpe O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-geo O     B-geo O    \n",
      "text :  He said last week 's tsunami and the massive underwater earthquake that triggered it has affected millions in Asia and Africa .\n",
      "\n",
      "-------------- 7\n",
      "score:  420.95068359375\n",
      "pred :  O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     O    \n",
      "text :  Some 1,27,000 people are known dead .\n",
      "\n",
      "-------------- 8\n",
      "score:  -2594.547607421875\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     B-org O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     O     O     O     O     B-geo O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "text :  Aid is being rushed to the region , but the U.N. official stressed that bottlenecks and a lack of infrastructure remain a challenge .\n",
      "\n",
      "-------------- 9\n",
      "score:  -2514.587646484375\n",
      "pred :  B-geo I-geo O     O     B-tim O     B-geo O     O     O     B-gpe O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  B-gpe O     O     O     B-tim O     O     O     O     O     O     O     O     B-geo O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "text :  Lebanese politicians are condemning Friday 's bomb blast in a Christian neighborhood of Beirut as an attempt to sow sectarian strife in the formerly war-torn country .\n",
      "\n",
      "-------------- 10\n",
      "score:  -5313.427734375\n",
      "pred :  O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-geo I-geo O     B-per O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "label:  O     B-geo O     O     O     O     O     O     O     O     O     O     O     O     B-org I-org O     O     B-geo I-geo O     B-per O     B-per I-per O     O     B-gpe O     O     O     O     O     O     O     O     O     O     O     O    \n",
      "text :  In Beirut , a string of officials voiced their anger , while at the United Nations summit in New York , Prime Minister Fouad Siniora said the Lebanese people are resolute in preventing such attempts from destroying their spirit .\n",
      "\n",
      "-------------- 11\n",
      "score:  -3186.16259765625\n",
      "pred :  O     O     O     O     O     O     O     O     <eos> <bos> O     O     O     O     O     B-tim O     O     O     O     O     O     O     O     O    \n",
      "label:  O     O     O     O     O     O     O     O     O     O     O     O     O     O     O     B-tim O     O     O     O     O     O     O     O     O    \n",
      "text :  One person was killed and more than 20 others injured in the bomb blast late Friday , which took place on a residential street .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(trainset):\n",
    "        sentence, tag = data\n",
    "        output = model(text_transform(sentence).unsqueeze(1))\n",
    "        score, tag_seq = viterbi_decode(output,model.transitions)\n",
    "        tag_seq = np.array(tag_seq).flatten().tolist()\n",
    "        decoded_seq = label_vocab.lookup_tokens(tag_seq)\n",
    "        print('--------------',i)\n",
    "        print('score: ', score.item())\n",
    "        print('pred : ', *[f'{d:<5}' for d in decoded_seq[1:-1]])\n",
    "        print('label: ', *[f'{t:<5}' for t in tag.split(' ')])\n",
    "        print('text : ', sentence)\n",
    "        print()\n",
    "        if i>10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [00:35<00:00, 10.46it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(trainloader)):\n",
    "        sentence, tag = data\n",
    "        mask = sentence.ne(PAD_IDX)\n",
    "        output = model(sentence)\n",
    "        score, tag_seq = viterbi_decode(output,model.transitions,mask=mask)\n",
    "        for b in range(len(tag_seq)):\n",
    "            tmp_yhat = torch.Tensor(tag_seq[b])\n",
    "            tmp_y = tag[:tag[:,b].ne(PAD_IDX).sum(),b]\n",
    "            assert tmp_yhat.size(0) == tmp_y.size(0), 'misaligned'\n",
    "            acc += tmp_y[1:-1].eq(tmp_yhat[1:-1]).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473807377815893"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc/len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 375/375 [00:48<00:00,  7.66it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = torch.zeros(len(label_vocab)-len(special_tokens))\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(trainloader)):\n",
    "        sentence, tag = data\n",
    "        mask = sentence.ne(PAD_IDX)\n",
    "        output = model(sentence)\n",
    "        score, tag_seq = viterbi_decode(output,model.transitions,mask=mask)\n",
    "        for b in range(len(tag_seq)):\n",
    "            tmp_yhat = torch.Tensor(tag_seq[b])\n",
    "            tmp_y = tag[:tag[:,b].ne(PAD_IDX).sum(),b]\n",
    "            assert tmp_yhat.size(0) == tmp_y.size(0), 'misaligned'\n",
    "            tmp_acc = tmp_y[1:-1].eq(tmp_yhat[1:-1]).float().div(len(tmp_y)-2)\n",
    "            for a,b in zip(tmp_y[1:-1],tmp_acc): acc[a-len(special_tokens)] += b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc O     : 82.4 %\n",
      "acc B-geo : 0.6 %\n",
      "acc B-tim : 0.5 %\n",
      "acc B-org : 0.1 %\n",
      "acc I-per : 0.2 %\n",
      "acc B-per : 0.5 %\n",
      "acc I-org : 0.1 %\n",
      "acc B-gpe : 0.2 %\n",
      "acc I-geo : 0.1 %\n",
      "acc I-tim : 0.0 %\n",
      "acc B-art : 0.0 %\n",
      "acc B-eve : 0.0 %\n",
      "acc I-art : 0.0 %\n",
      "acc I-eve : 0.0 %\n",
      "acc B-nat : 0.0 %\n",
      "acc I-gpe : 0.0 %\n",
      "acc I-nat : 0.0 %\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(label_vocab.get_itos()[len(special_tokens):],acc.div(len(trainset)).mul(1000).round().tolist()):\n",
    "    print(f'acc {a:<5} : {b/10} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "heatmap(model.transitions[2:,2:].div(-LIKELIHOOD_INIT).clone().detach().numpy().transpose(),\n",
    "        xticklabels=label_vocab.get_itos()[2:],      \n",
    "        yticklabels=label_vocab.get_itos()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
