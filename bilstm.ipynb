{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.datasets import CoNLL2000Chunking\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(lower=True, batch_first=True)\n",
    "LABEL = Field(batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val,test = CoNLL2000Chunking.splits(fields=[('text',TEXT),('label',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = BucketIterator.splits((train,test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeds = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            num_layers=2, bidirectional=True)\n",
    "        self.ln = nn.LayerNorm(hidden_dim*2)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, len(LABEL.vocab))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        tmp = self.word_embeds(sentence)\n",
    "        out, (ht,ct) = self.lstm(tmp)\n",
    "        out = self.ln(out)\n",
    "        out = self.hidden2tag(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(128,128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 46, 46])\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i in trainloader:\n",
    "        print(model(i.text.cuda()).shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 86.09it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 76.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0.04564186577860973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 85.83it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 74.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: 0.03389671413763872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 84.65it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 76.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: 0.029962785947800157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:03<00:00, 81.98it/s]\n",
      "  3%|██▎                                                                               | 7/252 [00:00<00:03, 68.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: 0.027595034836833378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:03<00:00, 83.17it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 79.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: 0.02616146685649613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 86.30it/s]\n",
      "  7%|█████▍                                                                           | 17/252 [00:00<00:02, 80.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: 0.02506223645221532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 84.82it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 76.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: 0.023933217433429244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 85.02it/s]\n",
      "  3%|██▌                                                                               | 8/252 [00:00<00:03, 72.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: 0.023290865462355814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 84.75it/s]\n",
      "  3%|██▎                                                                               | 7/252 [00:00<00:03, 69.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: 0.02263103076783735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 252/252 [00:02<00:00, 85.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: 0.022074661168759214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10): \n",
    "    running_loss = 0.0\n",
    "    for ss in tqdm(trainloader):\n",
    "        sentence, tags = ss.text, ss.label\n",
    "        sentence = sentence.cuda()\n",
    "        tags = tags.cuda()\n",
    "        \n",
    "        output = model(sentence).permute(0,2,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, tags)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "    print(f'epoch {epoch+1}: {running_loss/len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 252/252 [00:01<00:00, 229.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8013, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    acc = 0.0\n",
    "    for ss in tqdm(trainloader):\n",
    "        sentence, tags = ss.text, ss.label\n",
    "        sentence = sentence.cuda()\n",
    "        tags = tags.cuda()\n",
    "        \n",
    "        output = model(sentence).argmax(dim=-1)\n",
    "        acc += torch.sum(output == tags)/tags.size(1)\n",
    "    print(acc/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
