{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import Multi30k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'de'\n",
    "TRG_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = {\n",
    "    'de': get_tokenizer('spacy',language='de_core_news_sm'),\n",
    "    'en': get_tokenizer('spacy',language='en_core_web_sm')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_func(dataset, lang: str) -> List[str]:\n",
    "    for i in dataset:\n",
    "        yield token_transform[lang](i[0 if lang==SRC_LANGUAGE else 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transform = {\n",
    "    'de': '',\n",
    "    'en': ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in vocab_transform:\n",
    "\n",
    "    train_iter = Multi30k(split='train')\n",
    "    \n",
    "    vocab_transform[l] = build_vocab_from_iterator(iter_func(train_iter,l), \n",
    "                                                  specials=special_tokens,\n",
    "                                                  special_first=True)\n",
    "    \n",
    "    vocab_transform[l].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat([torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {\n",
    "    'de': sequential_transforms(token_transform[SRC_LANGUAGE],vocab_transform[SRC_LANGUAGE], tensor_transform),\n",
    "    'en': sequential_transforms(token_transform[TRG_LANGUAGE],vocab_transform[TRG_LANGUAGE], tensor_transform)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collate data samples into batch tesors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TRG_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    將欲翻譯句子轉為隱向量\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim = 128):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = embed_dim\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_transform[SRC_LANGUAGE]),embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim,self.hidden_dim,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tmp = self.embed(x)\n",
    "        o, (ht, ct) = self.rnn(tmp)\n",
    "        return ht, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    將隱向量與目標句子轉為欲翻譯句子\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embed_dim = 128):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = embed_dim\n",
    "        self.output_dim = len(vocab_transform[TRG_LANGUAGE])\n",
    "        \n",
    "        self.embed = nn.Embedding(self.output_dim,embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim,self.hidden_dim,1)\n",
    "        self.fc = nn.Linear(self.hidden_dim,self.output_dim)\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        tmp = x.unsqueeze(0)\n",
    "        tmp = self.embed(tmp)\n",
    "        o, (h, c) = self.rnn(tmp, (h, c))\n",
    "        o = o.squeeze(0)\n",
    "        o = self.fc(o)\n",
    "        return o, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        trg_len, batch_size = trg.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.full((trg_len, batch_size, trg_vocab_size), float(BOS_IDX)).cuda()\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input_seq = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, _, _ = self.decoder(input_seq, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input_seq = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder().cuda()\n",
    "dec = Decoder().cuda()\n",
    "model = Seq2Seq(enc,dec).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 32, 10838])\n"
     ]
    }
   ],
   "source": [
    "## 測試 forward\n",
    "for s,t in trainloader:\n",
    "    s,t = s.cuda(), t.cuda()\n",
    "    output = model(s,t)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:03<00:00, 14.38it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:58, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 : 0.1607525174535554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:03<00:00, 14.33it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:57, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 : 0.14542219115947855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:01<00:00, 14.85it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:55, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 : 0.13578977411368798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:02<00:00, 14.62it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:57, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 : 0.12786224468823137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:02<00:00, 14.44it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:55, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 : 0.12155147397107091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:01<00:00, 14.87it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:55, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 : 0.11617290838833513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:01<00:00, 14.87it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:55, 16.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 : 0.11218528918562264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:02<00:00, 14.58it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:57, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 : 0.10831787346971446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:02<00:00, 14.49it/s]\n",
      "  0%|▏                                                                                 | 2/907 [00:00<00:57, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 : 0.10448978164278228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 907/907 [01:04<00:00, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 : 0.10110897660255432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "training_loss = []\n",
    "for e in range(epoches):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    train_iter = Multi30k(split='train')\n",
    "    trainloader = DataLoader(train_iter, batch_size=32, collate_fn=collate_fn)\n",
    "    \n",
    "    for s,t in tqdm(trainloader):\n",
    "        text = s.cuda()\n",
    "        label = t.cuda()\n",
    "        \n",
    "        output = model(text,label)\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        label = label[1:].view(-1)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss = criterion(output,label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    training_loss.append(running_loss/len(train))\n",
    "    print(f'epoch {e+1} : {running_loss/len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2588da78670>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 34.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14418118381500244\n",
      "perplexity: 1.155093373790749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    test_iter = Multi30k(split='test')\n",
    "    testloader = DataLoader(test_iter, batch_size=32, collate_fn=collate_fn)\n",
    "    \n",
    "    for s, t in tqdm(testloader):\n",
    "        text, label = s.cuda(), t.cuda()\n",
    "        \n",
    "        output = model(text, label, 0)\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        label = label[1:].view(-1)\n",
    "        loss = criterion(output,label)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    final_loss = running_loss/len(test_iter)\n",
    "print(f'loss: {final_loss}')\n",
    "print(f'perplexity: {math.exp(final_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1句\n",
      "Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
      "A man in a orange hat is eating something\n",
      "第4句\n",
      "Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\n",
      "Five people are standing in the background\n",
      "第5句\n",
      "Leute Reparieren das Dach eines Hauses.\n",
      "People are working on the roof of a building\n",
      "第7句\n",
      "Eine Gruppe von Menschen steht vor einem Iglu.\n",
      "A group of people standing outside a building\n",
      "第10句\n",
      "Ein Mann in einer Weste sitzt auf einem Stuhl und hält Magazine.\n",
      "A man in a chair\n",
      "第12句\n",
      "Männer, die Volleyball spielen, wobei ein Mann denn Ball nicht trifft während seine Hände immer noch in der Luft sind.\n",
      "Men in the air\n",
      "第13句\n",
      "Eine Frau, die in einer Küche eine Schale mit Essen hält.\n",
      "A woman holding a hand\n",
      "第15句\n",
      "Drei Leute sitzen in einer Höhle.\n",
      "Three people sit on a park\n",
      "第21句\n",
      "Leute, die vor einem Gebäude stehen.\n",
      "People standing in front of a building\n",
      "第24句\n",
      "Ein Mann steht bei einigen Spielautomaten in einer Bar.\n",
      "A man is standing at a\n",
      "第28句\n",
      "Eine Gruppe Asiatischer Jungen wartet am Grill darauf, dass Fleisch gar wird.\n",
      "A group of people\n",
      "第29句\n",
      "Frauen, die traditionelle Kleidung tragen, spielen das Leben Einheimischer nach.\n",
      "Women in the\n",
      "第30句\n",
      "Ein Mann drückt den Kopf eines anderen Mannes nach unten und will ihm ins Gesicht schlagen.\n",
      "A man is to him\n",
      "第31句\n",
      "Sechs Leute fahren Mountainbikes durch eine Dschungellandschaft.\n",
      "Several people are through a track\n",
      "第33句\n",
      "Ein Kind planscht im Wasser.\n",
      "A child is jumping in the water\n",
      "第36句\n",
      "Ein Angestellter reicht einer Frau auf einem Markt eine Tüte, während sie auf Eis gelegten Fisch begutachtet.\n",
      "A woman on a market\n",
      "第41句\n",
      "Ein Mädchen in einer Rettungsweste treibt im Wasser.\n",
      "A girl in a water\n",
      "第43句\n",
      "Leute sitzen in einem Zug.\n",
      "People sitting in a\n",
      "第48句\n",
      "Eine Vaterfigur und zwei Kinder machen vor ihrem Zuhause Gartenarbeit wie den Rasen mit einer Gartenhacke zu bearbeiten und einen Baum zu pflanzen.\n",
      "A child , with a large\n",
      "第52句\n",
      "Ein Wakeboarder macht einen Salto während er bei hoher Geschwindigkeit an einem Seil gezogen wird.\n",
      "A horse is a\n",
      "第53句\n",
      "Eine große Menschenmenge säumt eine Straße.\n",
      "A large group of people\n",
      "第54句\n",
      "Ein Mann an einem Halteseil geht ins Wasser.\n",
      "A man is a the water\n",
      "第59句\n",
      "Der Mann in der gelben Hose hebt seine Arme.\n",
      "The man in a white\n",
      "第60句\n",
      "Zwei Männer mit Hüten und Spazierstöcken schlendern neben einem Gewässer bei Sonnenuntergang.\n",
      "Two men are sitting next to a\n",
      "第61句\n",
      "Ein Cheerleaderteam macht eine Übung auf Stühlen.\n",
      "A guy is on a\n",
      "第63句\n",
      "Eine Gruppe Menschen, die sich in einem öffentlichen Park amüsieren wollen.\n",
      "A group of people are in a park\n",
      "第64句\n",
      "Ein Mann sitzt auf einer Bank während er seinen Hund hält und aufs Wasser blickt.\n",
      "A man sitting on the ground\n",
      "第65句\n",
      "Ein Junge und sein jüngerer Bruder spielen gemeinsam auf einem Spielplatz.\n",
      "A boy and a game\n",
      "第67句\n",
      "Der braune Hund steht auf dem Sandstrand.\n",
      "The brown and white dog is sitting on the ground\n",
      "第70句\n",
      "Eine Frau singt in einem Klub mit einem Gitarristen hinter ihr.\n",
      "A woman is her\n",
      "第72句\n",
      "Ein Kind sitzt auf einem Gartenstuhl und sieht zur Kamera auf\n",
      "A child sitting on the ground\n",
      "第74句\n",
      "Eine Musikantin mit einer Violine spielt auf der Straße während eine Frau mit einer blauen Gitarre zusieht.\n",
      "A woman playing the street\n",
      "第75句\n",
      "Ein junges Mädchen schwimmt in einem Pool\n",
      "A young girl in a pool\n",
      "第76句\n",
      "Mehrere Kinder sind im Freien und bereiten sich auf Tauziehen vor.\n",
      "Several children are in the area\n",
      "第77句\n",
      "Drei Teenager in einer U-Bahn albern herum.\n",
      "Three men are in a\n",
      "第78句\n",
      "Ein Brauner Hund läuft durchs Gras und seine Zunge hängt heraus.\n",
      "A black dog running through the grass\n",
      "第79句\n",
      "Leute sitzen vor einem Gebäude im Gras und machen Pause.\n",
      "People are sitting in front of a building\n",
      "第81句\n",
      "Zwei Jungen packen Obst auf das Fahrrad.\n",
      "Two boys are riding a the ground\n",
      "第84句\n",
      "Zwei Spielerinnen der US-Nationalmannschaft klatschen im Sprung ab, umgeben von zwei weiteren Spielerinnen.\n",
      "Two older woman , two other\n",
      "第85句\n",
      "Ein Mann rührt in einem Topf in seiner Küche.\n",
      "A man is in a kitchen\n",
      "第86句\n",
      "Ein Junge beim Wakeboarden auf dem See.\n",
      "A boy is the ocean\n",
      "第92句\n",
      "Der Mann im japanischen Kochgewand bereitet ein Essen für zwei Personen zu.\n",
      "The man in a picture\n",
      "第95句\n",
      "Ein älterer Mann breitet seine Arme aus und blickt verblüfft.\n",
      "An older man is cutting his\n",
      "第97句\n",
      "Drei Männer in gleichfarbigen Westen halten sich im Freien auf.\n",
      "Three men in a\n",
      "第99句\n",
      "Eine Gruppe überwiegend asiatischer Kinder sitzt in Kabinen verteilt auf blauen Stühlen.\n",
      "A group of people sitting on a table\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 100\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_iter = Multi30k(split='test')\n",
    "    trg_vocab_size = len(vocab_transform[TRG_LANGUAGE])\n",
    "    \n",
    "    for i, (s, _) in enumerate(test_iter):\n",
    "        ori_text = s\n",
    "        s = text_transform[SRC_LANGUAGE](s.rstrip())\n",
    "        s = s.unsqueeze(1)\n",
    "        s = s.cuda()\n",
    "        \n",
    "        outputs = [BOS_IDX]\n",
    "        \n",
    "        h, c = model.encoder(s)\n",
    "        \n",
    "        for _ in range(MAX_LENGTH):\n",
    "            \n",
    "            input_seq = torch.LongTensor([outputs[-1]]).cuda()\n",
    "            \n",
    "            output, _, _ = model.decoder(input_seq, h, c)\n",
    "            \n",
    "            next_token = output.argmax(1).item()\n",
    "            outputs.append(next_token) \n",
    "            \n",
    "            if next_token == EOS_IDX: break\n",
    "        \n",
    "        if EOS_IDX in outputs:\n",
    "            translated = vocab_transform[TRG_LANGUAGE].lookup_tokens(outputs[1:-2])\n",
    "            print(f'第{i+1}句')\n",
    "            print(ori_text.rstrip())\n",
    "            print(*translated,sep=' ')\n",
    "        \n",
    "        if i==100: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'seq2seq.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('seq2seq.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
